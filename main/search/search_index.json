{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":""},{"location":"#eclipse-ankaios","title":"Eclipse Ankaios","text":"Watch Eclipse Ankaios presentation at Eclipse SDV community day on July 6, 2023 on Youtube"},{"location":"#scope","title":"Scope","text":"<p>Eclipse Ankaios provides workload and container orchestration for automotive High Performance Computing (HPC) software . While it can be used for various fields of applications, it is developed from scratch for automotive use cases and provides a slim yet powerful solution to manage containerized applications. It supports various container runtimes with Podman as the first one, but other container runtimes and even native applications can be supported. Eclipse Ankaios is independent of existing communication frameworks like SOME/IP, DDS, or REST API.</p> <p>Eclipse Ankaios manages multiple nodes and virtual machines with a single unique API in order to start, stop, configure, and update containers and workloads. It provides a central place to manage automotive applications with a setup consisting of one server and multiple agents. Usually one agent per node connects to one or more runtimes that are running the workloads.</p>"},{"location":"#next-steps","title":"Next steps","text":"<ul> <li>For first steps see installation and quickstart.</li> <li>An overview how Ankaios works is given on the architecture page.</li> <li>The API is described in the reference section.</li> <li>For contributions have a look at the development pages.</li> </ul>"},{"location":"#background","title":"Background","text":"<p>Eclipse Ankaios follows the UNIX philosophy to have one tool for one job and do that job well. It does not depend on a specific init system like systemd but can be started with any init system. It also does not handle persistency but can use  an existing automotive persistency handling, e.g. provided by AUTOSAR Adaptive.</p> <p>The workloads are provided access to the Eclipse Ankaios API using access control and thus are able to dynamically reconfigure the system. One possible use case is the dynamic startup of an application that is only required in a particular situation such as a parking assistant. When the driver wants to park the car, a control workload can start the parking assistant application. When the parking is finished, the parking assistant workload is stopped again.</p> <p>Eclipse Ankaios also provides a CLI that allows developers to develop and test configurations. In order to gain compatibility with Kubernetes, Eclipse Ankaios accepts pod specifications.</p> <p>An optional fleet connector can use the Eclipse Ankaios API to connect to a cloud-based software update system, which allows an OEM to manage a fleet of vehicles and provide new states to Eclipse Ankaios in order to update single or all applications.</p> <p>In order to support the Automotive SPICE process, Eclipse Ankaios comes with requirements tracing supported by OpenFastTrace.</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>Two executables are used for each Ankaios deployment: the Ankaios server and the Ankaios agent.</p> <p></p> <p>When started, the Ankaios server loads the configured startup state of the cluster and stores it as a desired state. To reach this desired state, the server instructs the Ankaios agents to start and stop workloads. Each Ankaios cluster runs exactly one instance of the Ankaios server making the server the single source of truth.</p> <p>A running instance of the Ankaios agent is present on every node where Ankaios needs to execute workloads. The Ankaios agent is responsible for starting and stopping workloads, according to the commands it gets from the Ankaios server.</p> <p>The Ankaios server itself does not run workloads directly so in order to start workloads on the node running the server, an Ankaios agent shall be started there too.</p> <p>Ankaios provides an interface, which allows workloads to change the desired state stored in the Ankaios server. Workloads access this interface by sending their requests to the Ankaios agent managing them. Each request is checked by the Ankaios agent and, on successful authorization, forwarded to the Ankaios server. This interface can be used to e.g.:</p> <ul> <li>Dynamically reconfigure the system to start a parking assistant.</li> <li>Start additional workloads requested by a backend to collect data about the road condition.</li> </ul> <p>In the diagram above one of the workloads on node 1 acts as fleet connector. It accesses a backend and forwards commands to the Ankaios server. In the example below the fleet connector gets an update from the backend, which adds a workload to node 2.</p> <p></p>"},{"location":"architecture/#notes","title":"Notes","text":"<ul> <li>Ankaios uses gRPC for communication between the Ankaios server and the Ankaios agents,   but the internal structure of Ankaios allows to replace gRPC with another communication protocol.</li> <li>The communication between workloads is not in the scope of Ankaios.   The communication must be set up separately,   which allows to use any technology needed for the project, e.g. network, named pipes, unix sockets or shared memory.</li> </ul>"},{"location":"development/build/","title":"Build","text":""},{"location":"development/build/#dev-container","title":"Dev container","text":"<p>The repo provides a Visual Studio Code dev container which includes all necessary tools to build all components and the documentation, but it does not provide the tools to run Ankaios as it's not the target platform. In case you want to extend the dev container see extending the dev container.</p>"},{"location":"development/build/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker (Installation instructions)</li> <li>Microsoft's Visual Studio Code Extension Dev Containers</li> </ul>"},{"location":"development/build/#build-ankaios","title":"Build Ankaios","text":"<p>To build and test the Ankaios agent and server, run the following command inside the dev container:</p> <pre><code>cargo build\n</code></pre> <p>and for release</p> <pre><code>cargo build --release\n</code></pre>"},{"location":"development/build/#build-for-arm64-target-on-x86-host","title":"Build for arm64 target on x86 host","text":"<p>The dev container adds required tools for <code>arm64</code> architecture. To build Ankaios for <code>arm64</code>, run the following command inside the dev container:</p> <pre><code>cargo build --target aarch64-unknown-linux-gnu --release\n</code></pre>"},{"location":"development/ci-cd-release/","title":"CI/CD - Release","text":"<p>A release shall be built directly using the CI/CD environment Github Actions. The release build creates and uploads all necessary artifacts that are required for a release.</p>"},{"location":"development/ci-cd-release/#release-workflow","title":"Release workflow","text":"<p>For building a release a separate workflow exists inside <code>.github/workflows/release.yml</code>. The release workflow reuses the complete build workflow from <code>.github/workflows/build.yml</code> and its artifacts.</p> <p>This allows to avoid having to duplicate the steps of the build workflow into the release workflow  and thus have a single point of change for the build workflow.</p> <p>The release workflow executes the build workflow, exports the build artifacts into an archive for each supported platform and uploads it to the Github release.</p> <p>As an example the following release artifacts are created for linux-amd64:</p> <ul> <li>ankaios-linux-amd64.tar.gz</li> <li>ankaios-linux-amd64.tar.gz.sha512sum.txt</li> </ul> <p>The tar.gz archive contains the pre-built binaries for the Ankaios CLI, Ankaios server and Ankaios agent. The *.sha512sum.txt file contains the sha-512 hash of the archive.</p>"},{"location":"development/ci-cd-release/#release-scripts","title":"Release scripts","text":"<p>To package the desired release artifacts a separate script <code>tools/create_release.sh</code> is called inside the release job. The script calls another script <code>tools/create_artifacts.sh</code> for each platform that creates the artifacts mentioned above.</p> <p>In addition, it exports the following:</p> <ul> <li>Coverage report</li> <li>Requirements tracing teport</li> <li>ankaios.proto</li> <li>install.sh (Ankaios installation script)</li> </ul> <p>Within the release workflow the build artifacts are downloaded into a temporary folder called <code>dist</code> which has the following structure:</p> <pre><code>\u251c\u2500\u2500 coverage\n\u2502   \u251c\u2500\u2500 index.html\n\u2502   \u2514\u2500\u2500 style.css\n\u251c\u2500\u2500 linux-amd64\n\u2502   \u2514\u2500\u2500 bin\n\u2502       \u251c\u2500\u2500 ank\n\u2502       \u251c\u2500\u2500 ank-agent\n\u2502       \u2514\u2500\u2500 ank-server\n\u251c\u2500\u2500 linux-arm64\n\u2502   \u2514\u2500\u2500 bin\n\u2502       \u251c\u2500\u2500 ank\n\u2502       \u251c\u2500\u2500 ank-agent\n\u2502       \u2514\u2500\u2500 ank-server\n\u2514\u2500\u2500 req_tracing_report.html\n</code></pre> <p>The platform specific files are downloaded into a sub-folder <code>dist/&lt;os&gt;-&lt;platform&gt;/bin</code>. Reports and shared artifacts are placed into the <code>dist</code> folder directly.</p> <p>The scripts expect this folder structure to create final release artifacts.</p>"},{"location":"development/ci-cd-release/#adding-a-new-platform","title":"Adding a new Platform","text":"<p>If a new platform shall be supported the following steps must be done:</p> <ol> <li>If not already done, add a build job for the new platform in <code>.github/workflows/build.yml</code> and configure the upload of the artifacts, see CI/CD section.</li> <li>Configure the release workflow under <code>.github/workflows/release.yml</code> to download the new artifacts.    Under <code>jobs.release.steps</code> add a new step after the existing download steps and replace the parameters <code>&lt;os&gt;-&lt;platform&gt;</code> with the correct text (e.g. linux-amd64):    <pre><code> jobs:\n   ...\n   release:\n     steps:\n     ...\n     - name: Download artifacts for ankaios-&lt;os&gt;-&lt;platform&gt;-bin\n       uses: actions/download-artifact@v3.0.2\n       with:\n         name: ankaios-&lt;os&gt;-&lt;platform&gt;-bin\n         path: dist/&lt;os&gt;-&lt;platform&gt;/bin\n     ...\n</code></pre>    The name <code>ankaios-&lt;os&gt;-&lt;platform&gt;-bin</code> must match the used name in the upload artifact action defined inside the build workflow (<code>.github/workflows/build.yml</code>).</li> <li> <p>Inside <code>tools/create_release.sh</code> script add a new call to the script <code>tools/create_artifacts.sh</code> like the following:    <pre><code>...\n \"${SCRIPT_DIR}\"/create_artifacts.sh -p &lt;os&gt;-&lt;platform&gt;\n...\n</code></pre>    The <code>&lt;os&gt;-&lt;platform&gt;</code> string must match the name of the sub-folder inside the dist folder. The called script expects the pre-built binaries inside <code>&lt;os&gt;-&lt;platform&gt;/bin</code>.</p> </li> <li> <p>Configure the upload of the new release artifact in the release workflow inside <code>.github/workflows/release.yml</code>.    Inside the step that uploads the release artifacts add the new artifact(s) to the github upload command:    <pre><code>...\nrun: |\n  gh release upload ${{ github.ref_name }}\n   ...\n   &lt;os&gt;-&lt;platform&gt;/ankaios-&lt;os&gt;-&lt;platform&gt;.tar.gz \\\n   &lt;os&gt;-&lt;platform&gt;/ankaios-&lt;os&gt;-&lt;platform&gt;.tar.gz.sha512sum.txt\n   ...\n</code></pre></p> </li> <li>Test and run the release workflow and check if the new artifact is uploaded correctly.</li> <li>Validate if the platform auto-detect mechanism of the installation script is supporting the new platform <code>tools/install.sh</code> and update the script if needed.</li> </ol>"},{"location":"development/ci-cd-release/#release-notes","title":"Release notes","text":"<p>The release notes are generated automatically if a release is created via the Github web frontend by clicking on the <code>Generate release notes</code> button.</p> <p>The procedure uses the filters for pull request labels configured inside <code>.github/release.yml</code>.</p>"},{"location":"development/ci-cd-release/#building-a-release","title":"Building a release","text":"<p>The release shall be created directly via the Github web frontend.</p> <p>When creating a release a tag with the following naming convention must be provided: <code>vX.Y.Z</code> (e.g. v0.1.0).</p> <ol> <li>Go to the release section inside the repository and click on <code>Draft a new release</code>.</li> <li>Choose the tag to be created on publish.</li> <li>As release name enter the same tag.</li> <li>Click on the button <code>Generate release notes</code> to generate the release notes automatically based on the filter settings for pull requests inside <code>.github/release.yml</code> configuration. In case of unwanted pull requests are listed, label the pull requests correctly, delete the description field and generate the release notes again (The correction of the labels and the regeneration of the release notes can also be done after the release build.).</li> <li>Make sure that the check box <code>Set as the latest release</code> is enabled. This setting is important otherwise the provided link for the installation script in chapter installation is still pointing to the previous release marked as latest.</li> <li>Click on <code>Publish release</code>.</li> <li>Go to Github Actions section and wait until the release workflow has finished.</li> <li>If the release build finished successfully, go to the release section again and validate that all required artifacts are uploaded to the new release.</li> <li>If the release workflow fails, delete the release and the tag manually via the Github web frontend. Next, check the logs of the release workflow and fix the issues. Repeat the steps starting at step 1.</li> </ol> <p>Note</p> <p>There is a Github Action available to automatically rollback the created release and tag. This action is not used to have a better control over the cleanup procedure before a next release build is triggered. For instance, without auto-rollback a manually entered release description is still available after a failing release build.</p>"},{"location":"development/ci-cd/","title":"CI/CD","text":"<p>As CI/CD environment Github Actions is used. Merge verifications in case of opening a pull request and release builds are fully covered into Github Action workflows. For information about release builds, see CI/CD - Release section.</p>"},{"location":"development/ci-cd/#merge-verification","title":"Merge verification","text":"<p>When a pull request is opened, the following pipeline jobs run:</p> <ul> <li>Linux-amd64 release build + tests in debug mode</li> <li>Linux-amd64 coverage test report</li> <li>Linux-arm64 release build (cross platform build)</li> <li>Requirements tracing</li> </ul> <p>After a pull request was merged into the main branch, the jobs listed above are executed again to validate stable branch behavior.</p> <p>The steps for the build workflow are defined inside <code>.github/workflows/build.yml</code>.</p> <p>The produced artifacts of the build workflow are uploaded and  can be downloaded from Github for debugging or testing purposes.</p>"},{"location":"development/ci-cd/#adding-a-new-merge-verification-job","title":"Adding a new merge verification job","text":"<p>To add a new merge verification job adjust the workflow defined inside <code>.github/workflows/build.yml</code>.</p> <p>Select a Github runner image matching your purposes or in case of adding a cross-build first make sure that the build works locally within the dev container.</p> <ol> <li>Add a new build job under the <code>jobs</code> jobs section and define a job name.</li> <li>Add the necessary steps to the job to build the artifact(s).</li> <li>Append a use clause to the build steps to upload the artifacts to Github. If a new platform build is added name the artifact according to the naming convention <code>ankaios-&lt;os&gt;-&lt;platform&gt;-bin</code> (e.g. ankaios-linux-amd64-bin) otherwise define a custom name. If the artifact is needed inside a release the artifact is referenced with this name inside the release workflow.    <pre><code> ...\n  - uses: actions/upload-artifact@v3.1.2\n    with:\n      name: ankaios-&lt;os&gt;-&lt;platform&gt;-bin\n      path: dist/\n ...\n</code></pre></li> </ol> <p>Note</p> <p>Github Actions only runs workflow definitions from main (default) branch. That means when a workflow has been changed and a PR has been created for that, the change will not become effective before the PR is merged in main branch. For local testing the act tool can be used.</p>"},{"location":"development/ci-cd/#adding-a-new-github-action","title":"Adding a new Github action","text":"<p>When introducing a new github action, do not use a generic major version tag (e.g. <code>vX</code>). Specify a specific release tag (e.g. <code>vX.Y.Z</code>) instead. Using the generic tag might lead to an unstable CI/CD environment, whenever the authors of the Github action update the generic tag to point to a newer version that contains bugs or incompatibilities with the Ankaios project.</p> <p>Example:</p> <p>Bad: <pre><code>...\n  - uses: actions/checkout@v3\n...\n</code></pre></p> <p>Good: <pre><code>...\n  - uses: actions/checkout@v3.5.3\n...\n</code></pre></p>"},{"location":"development/documentation-guidelines/","title":"Documentation guidelines","text":"<p>These guidelines apply to all documentation which is created in the Ankaios project like this website, software design documents or README files. The aim is to support the creators of documents by enforcing a common look and feel.</p>"},{"location":"development/documentation-guidelines/#capitalization","title":"Capitalization","text":"<p>As 'Ankaios' is a proper noun it shall be written with a capital 'A'. Other words which are not proper nouns shall be in lower case when they are not the first word in a sentence.</p> <p>Examples:</p> Correct Incorrect Ankaios ankaios Ankaios server Ankaios-Server, Ankaios-server, Ankaios Server Ankaios agent Ankaios-Agent, Ankaios-agent, Ankaios Agent workload Workload control interface Control Interface <p>The same rule also applies to headlines, i.e. only the first word of a headline is in upper case.</p>"},{"location":"development/extending-dev-container/","title":"Extending the dev container","text":"<p>The dev container is relatively large so we have split a base container which is available from <code>ghcr.io/eclipse-ankaios/devcontainer</code>.</p> <p>If there is a need to include additional items in the dev container, please note that it is split into two parts due to its size:</p> <ul> <li> <p>a base container which, in case of a change, needs to be build manually from .devcontainer/Dockerfile.base by running the following outside of the dev container:</p> <pre><code># Prepare the build with buildx. Depending on you environment\n# the following steps might be necessary:\ndocker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n# Create and use a new builder. This needs top be called only once:\ndocker buildx create --name mybuilder --driver docker-container --bootstrap\ndocker buildx use mybuilder\n\n# Now build new base image for the dev container\ncd .devcontainer\ndocker buildx build -t ghcr.io/eclipse-ankaios/devcontainer-base:&lt;version&gt; --platform linux/amd64,linux/arm64 -f Dockerfile.base .\n</code></pre> <p>In order to push the base image append <code>--push</code> to the previous command.</p> <p>Note: If you wish to locally test the base image in VSCode before proceeding, utilize the default builder and exclusively build for the default platform like</p> <pre><code>docker buildx use default\ndocker buildx build -t ghcr.io/eclipse-ankaios/devcontainer-base:&lt;version&gt; -f Dockerfile.base --load .\n</code></pre> </li> <li> <p>a docker container which derives from the base image mentioned above is specified in <code>.devcontainer/Dockerfile</code> (so don't forget to reference your new version there once you build one).</p> </li> </ul> <p>If you want to add some additional tools, you can initially do it in <code>.devcontainer/Dockerfile</code>, but later on they need to be pulled in the the base image at some point in order to speed up the initial dev container build.</p>"},{"location":"development/requirement-tracing/","title":"Requirements tracing","text":"<p>The Eclipse Ankaios project provides requirements tracing using the Open Fast Trace requirement tracing suite. The dev container already includes an <code>oft</code> executable and supports the <code>oft</code> command. For convenience, you can run the <code>tools/generate_oft_html_report.sh</code> script to automatically generate an HTML report showing the current coverage state. The script automatically includes all src and doc folders in the root folder. As long as you name your folders accordingly they will be processed by <code>oft</code>. </p> <p>For details on the <code>oft</code> tool, please consult the user documentation or execute <code>oft help</code>.</p>"},{"location":"development/run-unit-tests/","title":"Run unit tests","text":"<p>If you want to run all unit tests without traces, call in the root of the project:</p> <pre><code>cargo test\n</code></pre> <p>Some unit tests can print trace logs. If you want to see them, you have to set the <code>RUST_LOG</code> environment variable before running unit tests. The tests in the agent are multithreaded. Tests are not stated one-by-one, but tests are started in parallel in its own threads. This makes difficult to read trace logs, because it is hard to find which trace belongs to which test. If you want to have traces sorted by unit tests, call this (recommended):</p> <pre><code>cargo test -- --show-output\n</code></pre> <p>Rust also allows to run only a subset of unit tests. You have to se the \"filter string\" in the command:</p> <pre><code>cargo test &lt;filter string&gt; [-- --show-output]\n</code></pre> <p>Where the <code>filter string</code> is part of unit test name. For example we have a unit test with the name:</p> <pre><code>test podman::workload::container_create_success\n</code></pre> <p>If you want to call only this test, you can call:</p> <pre><code>cargo test workload::container_create_success [-- --show-output]\n</code></pre> <p>If you want to call all tests in <code>workload.rs</code>, you have to call:</p> <pre><code>cargo test podman::workload [-- --show-output]\n</code></pre> <p>You can also call only tests in <code>workload.rs</code>, which have a name starting with <code>container</code>:</p> <pre><code>cargo test podman::workload::container [-- --show-output]\n</code></pre>"},{"location":"development/rust-coding-guidelines/","title":"Rust coding guidelines","text":"<p>When engaging in collaborative software projects, it is crucial to ensure that the code is well-organized and comprehensible. This facilitates ease of maintenance and allows for seamless extension of the project. To accomplish this objective, it is essential to establish shared guidelines that the entire development team adheres to.</p> <p>The goal is to get a harmonized code-base which appears to come from the same hands. This simplifies reading and understanding the intention of the code and helps maintaining the development speed.</p> <p>The following chapters describe rules and concepts to fit clean code expectations.</p>"},{"location":"development/rust-coding-guidelines/#clean-code","title":"Clean code","text":"<p>We like our code clean and thus use the \"Clean Code\" rules from \"uncle Bob\". A short summary can be found here. </p> <p>As rust could get a bit messy, feel free to add some additional code comments to blocks that cannot be made readable using the clean code rules.</p>"},{"location":"development/rust-coding-guidelines/#naming-conventions","title":"Naming conventions","text":"<p>We follow the standard Rust naming conventions.</p> <p>Names of components, classes , functions, etc. in code should also follow the prescriptions in SW design. Before thinking of new names, please make sure that we have not named the beast already.</p> <p>Names of unit tests within a file shall be hierarchical. Tests which belong together shall have the same prefix. For example the file <code>workload.rs</code> contains following tests:</p> <ul> <li><code>container_create_success</code></li> <li><code>container_create_failed</code></li> <li><code>container_start_success</code></li> <li><code>container_start_failure_no_id</code></li> </ul> <p>So if you want to call tests which work with container, you can write</p> <pre><code>cargo test container\n</code></pre> <p>If you want to call tests of the \"container create\" function, you can call:</p> <pre><code>cargo test container_create\n</code></pre> <p>More information about calling unit tests is in The Rust Programming Language.</p>"},{"location":"development/rust-coding-guidelines/#logging-conventions","title":"Logging conventions","text":"<p>The following chapters describe rules for creating log messages.</p>"},{"location":"development/rust-coding-guidelines/#log-format-of-internal-objects","title":"Log format of internal objects","text":"<p>When writing log messages that reference internal objects, the objects shall be surrounded in single quotes, e.g.:</p> <pre><code>log::info!(\"This is about object '{}'.\", object.name)\n</code></pre> <p>This helps differentiate static from dynamic data in the log message.</p>"},{"location":"development/rust-coding-guidelines/#log-format-of-multiline-log-messages","title":"Log format of multiline log messages","text":"<p>Multi line log messages shall be created with the <code>concat!</code> macro, e.g.:</p> <pre><code>log::debug!(concat!(\n\"First line of a log message that lists something:\\n\",\n\"   flowers are: '{}'\\n\",\n\"   weather is: {}\")\ncolor, current_weather);\n</code></pre> <p>This ensures that the log messages are formatted correctly and simplifies writing the message.</p>"},{"location":"development/rust-coding-guidelines/#choose-a-suitable-log-severity","title":"Choose a suitable log severity","text":"Severity Use Case Trace A log that is useful for diagnostic purposes and/or more granular than severity debug. Debug A log that is useful for developers meant for debugging purposes or hit very often. Info A log communicating important information like important states of an application suitable for any kind of user and that does not pollute the output. Warn A log communicating wrong preconditions or occurrences of something unexpected but do not lead to a panic of the application. Error A log communicating failures and consequences causing a potential panic of the application."},{"location":"development/rust-coding-guidelines/#unit-test-convenience-rules","title":"Unit test convenience rules","text":"<p>The following chapter describes important rules about how to write unit tests.</p>"},{"location":"development/rust-coding-guidelines/#test-mockobject-generation","title":"Test mock/object generation","text":"<p>When writing tests, one of the most tedious task is to setup the environment and create the necessary objects and/or mocks to be able to test the desired functionality. Following the DRY principle and trying to save some effort, we shall always place the code that generates a test or mock object in the same module/file where the mock of the object is defined.</p> <p>For example, when you would like to generate and reuse a mock for the <code>Directory</code> structure located in the <code>agent/src/control_interface/directory.rs</code> file, you shall</p> <ul> <li> <p>write a public setup function:   <pre><code>pub fn generate_test_directory_mock() -&gt; __mock_MockDirectory::__new::Context;\n</code></pre>   The <code>&lt;datatype_name&gt;</code> in <code>__mock_Mock&lt;datatype_name&gt;::__new::Context</code> must be replaced with the name of the type the mock is created for.</p> </li> <li> <p>place the function in the test part of the file (after the test banner if you use one)</p> </li> <li>place a <code>#[cfg(test)]</code> (or <code>#[cfg(feature = \"test_utils\")]</code> in case of a library) before the function to restrict its compilation to test only</li> <li>use this function in all places where you need</li> <li>If you need some variation in the output or the behavior of the function, you can, of course, make it parametrized.</li> </ul> <p>All object/mock generation functions shall start with <code>generate_test_</code>.</p>"},{"location":"development/rust-coding-guidelines/#advanced-rules","title":"Advanced rules","text":""},{"location":"development/rust-coding-guidelines/#don-t-reinvent-the-wheel","title":"Don' t reinvent the wheel","text":"<p>Bad:</p> <pre><code>let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8];\nlet mut filtered_numbers = Vec::new();\n// filter numbers smaller then 3\nfor number in numbers {\nif number &lt; 3 {\nfiltered_numbers.push(number);\n}\n}\n</code></pre> <p>Good:</p> <p>Prefer standard library algorithms over own implementations to avoid error prone code.</p> <pre><code>let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8];\nlet filtered_numbers: Vec&lt;i32&gt; = numbers.into_iter().filter(|x| x &lt; &amp;3).collect();\n</code></pre>"},{"location":"development/rust-coding-guidelines/#prefer-error-propagation","title":"Prefer error propagation","text":"<p>Bad:</p> <p>A lot of conditionals for opening and reading a file.</p> <pre><code>use std::fs::File;\nuse std::io;\nuse std::io::Read;\nfn read_from_file(filepath: &amp;str) -&gt; Result&lt;String, io::Error&gt; {\nlet file_handle = File::open(filepath);\nlet mut file_handle = match file_handle {\nOk(file) =&gt; file,\nErr(e) =&gt; return Err(e),\n};\nlet mut buffer = String::new();\nmatch file_handle.read_to_string(&amp;mut buffer) {\nOk(_) =&gt; Ok(buffer),\nErr(e) =&gt; Err(e)\n}\n}\n</code></pre> <p>Good:</p> <p>Prefer error propagation over exhaustive match and conditionals.</p> <p>Error propagation shortens and cleans up the code path by replacing complex and exhaustive conditionals  with the <code>?</code> operator without loosing the failure checks.</p> <p>The refactored variant populates the error and success case the same way to the caller like in the bad example above, but is more readable: <pre><code>fn read_from_file(filepath: &amp;str) -&gt; Result&lt;String, io::Error&gt; {\nlet mut buffer = String::new();\nFile::open(filepath)?.read_to_string(&amp;mut buffer)?;\nOk(buffer)\n}\n</code></pre></p> <p>In case of mismatching error types, provide a custom From-Trait implementation  to convert between error types to keep the benefits of using the <code>?</code> operator.  But keep in mind that error conversion shall be used wisely (e.g. for abstracting third party library error types or if there is a benefit to introduce a common and reusable error type).  The code base shall not be spammed with From-Trait implementations to replace each single match or conditional.</p> <p>Error propagation shall also be preferred when converting between <code>Result&lt;T,E&gt;</code> and <code>Option&lt;T&gt;</code>.</p> <p>Bad: </p> <pre><code>fn string_to_percentage(string: &amp;str) -&gt; Option&lt;f32&gt; {\n// more error handling\nmatch string.parse::&lt;f32&gt;() {\nOk(value) =&gt; Some(value * 100.),\n_ =&gt; None,\n}\n}\n</code></pre> <p>Good:</p> <pre><code>fn string_to_percentage(string: &amp;str) -&gt; Option&lt;f32&gt; {\n// more error handling\nlet value = string.parse::&lt;f32&gt;().ok()?; // returns None on parsing error\nSome(value * 100.)\n}\n</code></pre>"},{"location":"development/rust-coding-guidelines/#avoid-unwrap-and-expect","title":"Avoid unwrap and expect","text":"<p><code>Unwrap</code> or <code>expect</code> return the value in success case or call the <code>panic!</code> macro if the operation has failed. Applications that are often terminated directly in case of errors are considered as unprofessional and not useful.</p> <p>Bad: <pre><code>let value = division(10, 0).unwrap(); // panics, because of a simple division!!!\n</code></pre></p> <p>Good:</p> <p>Replace <code>unwrap</code> or <code>expect</code> with a conditional check, e.g. match expression:</p> <pre><code>let value = division(10, 0); // division 10 / 0 not allowed, returns Err\n// conditional check before accessing the value\nmatch value {\nOk(value) =&gt; println!(\"{value}\"),\nErr(e) =&gt; eprintln!(\"{e}\")\n}\n</code></pre> <p>or with if-let condition when match is awkward:</p> <pre><code>// access value only on success\nif let Ok(value) = division(10, 0) {\nprintln!(\"{value}\")\n}\n</code></pre> <p>or if possible continue with some default value in case of an error:</p> <pre><code>let result = division(10, 0).unwrap_or(0.);\n</code></pre> <p>Exceptions:</p> <p>In some cases terminating a program might be necessary. To make a good decision when to panic a program or not, the official rust book might help: To panic! or Not to panic!</p> <p>When writing unit tests using <code>unwrap</code> helps to keep tests short and to concentrate on the <code>assert!</code> statements:</p> <p>Bad:</p> <pre><code>let container: Option&lt;HashMap&lt;i32, String&gt;&gt; = operation_under_test();\nmatch container {\nSome(container) =&gt; {\nmatch container.get(&amp;0) {\nSome(value_of_0) =&gt; assert_eq!(value_of_0, &amp;\"hello world\".to_string()),\n_ =&gt; { panic!(\"Test xy failed, no entry.\") }\n}\n},\n_ =&gt; { panic!(\"Test xy failed, no container.\") }\n}\n</code></pre> <p>Good:</p> <p>Prefer direct <code>unwrap</code> calls over <code>assert!</code> statements nested in complex conditional clauses. It is shorter and the <code>assert!</code> statement is directly eye-catching.</p> <pre><code>let container: Option&lt;HashMap&lt;i32, String&gt;&gt; = operation_under_test();\nlet value_of_0 = container.unwrap().remove(&amp;0).unwrap(); // the test is failing on error\nassert_eq!(value_of_0, \"hello world\".to_string());\n</code></pre>"},{"location":"development/rust-coding-guidelines/#prefer-while-let-over-match-in-loops","title":"Prefer while-let over match in loops","text":"<p>Use the shorter and cleaner while-let expression to eliminate exhaustive match sequences in loops:</p> <p>Bad:</p> <pre><code>loop {\nmatch generate() {\nSome(value) =&gt; println!(\"{value}\"),\n_ =&gt; { break; },\n}\n}\n</code></pre> <p>Good:</p> <pre><code>// if success use the value else break\n// ...or while let Ok(value) in case of Result&lt;T,E&gt; instead of Option&lt;T&gt;\nwhile let Some(value) = generate() {\nprintln!(\"{value}\")\n}\n</code></pre>"},{"location":"development/rust-coding-guidelines/#prefer-lazily-evaluated-functional-chaining","title":"Prefer lazily evaluated functional chaining","text":"<p>Bad:</p> <p>Eagerly evaluated functions are always evaluated regardless of the success or error case. If the alternative is not taken potentially costly operations are performed unnecessarily.</p> <pre><code>let value = division(2., 10.);\nlet result = value.and(to_percentage(value)); // eagerly evaluated\nlet value = division(2., 10.);\nlet result = value.or(provide_complex_alternative()); // eagerly evaluated\nlet value = division(2., 10.);\nlet result = value.unwrap_or(generate_complex_default()); // eagerly evaluated\n</code></pre> <p>Good:</p> <p>Lazily evaluated functions are only evaluated if the case actually occurs and are preferred if the alternatives provide costly operations.</p> <pre><code>let result = division(2., 10.).and_then(to_percentage); // lazily evaluated\nlet result = division(2., 10.).or_else(provide_complex_alternative); // lazily evaluated\nlet result = division(2., 10.).unwrap_or_else(generate_complex_default); // lazily evaluated\n</code></pre>"},{"location":"development/rust-coding-guidelines/#avoid-exhaustive-nested-code","title":"Avoid exhaustive nested code","text":"<p>Bad:</p> <p>The code is hard to read and the interesting code path is not an eye-catcher.</p> <pre><code>fn list_books(&amp;self) -&gt; Option&lt;Vec&lt;String&gt;&gt; {\nif self.wifi {\nif self.login {\nif self.admin {\nreturn Some(get_list_of_books());\n} else {\neprintln!(\"Expected login as admin.\");\n}\n} else {\neprintln!(\"Expected login.\");\n}\n} else {\neprintln!(\"Expected connection.\");\n}\nNone\n}\n</code></pre> <p>Good:</p> <p>Nest code only into 1 or 2 levels. Use early-exit pattern to reduce the nest level and to separate error handling code from code doing the actual logic.</p> <pre><code>fn list_books(&amp;self) -&gt; Option&lt;Vec&lt;String&gt;&gt; {\nif !self.wifi {\neprintln!(\"Expected connection.\");\nreturn None;\n}\nif !self.login {\neprintln!(\"Expected login.\");\nreturn None;\n}\nif !self.admin {\neprintln!(\"Expected login as admin.\");\nreturn None;\n} // interesting part\nSome(get_list_of_books())\n}\n</code></pre> <p>As an alternative, when dealing with <code>Option&lt;T&gt;</code> or <code>Result&lt;T,E&gt;</code> use Rust's powerful combinators to keep the code readable.</p>"},{"location":"development/rust-coding-guidelines/#follow-common-rust-principles-and-idioms","title":"Follow common Rust principles and idioms","text":"<p>Understanding and practicing important Rust idioms help to write code in an idiomatic way, meaning resolving a task by following the conventions of a given language. Writing idiomatic Rust code ensures a clean and consistent code base. Thus, please follow the guidelines of Idiomatic Rust.</p>"},{"location":"development/rust-coding-guidelines/#avoid-common-anti-patterns","title":"Avoid common anti-patterns","text":"<p>There are a lot of Rust anti-patterns that shall not be used in general. To get more details about anti-patterns, see here.</p>"},{"location":"development/rust-coding-guidelines/#dont-make-sync-code-async","title":"Don't make sync code async","text":"<p>Async code is mainly used for I/O intensive, network or background tasks (Databases, Servers) to allow executing such tasks in a non-blocking way, so that waiting times can be used reasonably for executing other operations. However operations that do not fit to async use cases and are called synchronously shall not be made async because there is no real benefit. Async code is more difficult to understand than synchronous code.</p> <p>Bad:</p> <p>No need for making those operations async, because they are exclusively called synchronously. It is just more syntax and the code raises more questions about the intent to the reader. <pre><code>let result1 = operation1().await;\nlet result2 = operation2().await;\nlet result3 = operation3().await;\n</code></pre></p> <p>Good:</p> <p>Keep it synchronous and thus simple. <pre><code>let result1 = operation1();\nlet result2 = operation2();\nlet result3 = operation3();\n</code></pre></p>"},{"location":"development/rust-coding-guidelines/#dont-mix-sync-and-async-code-without-proper-consideration","title":"Don\u2019t mix sync and async code without proper consideration","text":"<p>Mixing sync and async code can lead to a number of problems, including performance issues, deadlocks, and race conditions. Avoid mixing async with sync code unless there is a good reason to do so.</p>"},{"location":"development/rust-coding-guidelines/#further-readings","title":"Further Readings","text":"<ul> <li>https://rustc-dev-guide.rust-lang.org/conventions.html</li> <li>https://www.kernel.org/doc/html/next/rust/coding-guidelines.html</li> <li>https://rust-lang.github.io/api-guidelines/about.html</li> </ul>"},{"location":"development/test-coverage/","title":"Test coverage","text":"<p>To generate the test coverage report, run the following commands in <code>ankaios</code> workspace which is <code>/home/vscode/workspaces/ankaios/</code>:</p> <p>To print out directly into the console: <pre><code>cov test\n</code></pre></p> <p>Or to produce a report in html:</p> <p><pre><code>cov test --html\n</code></pre> The script outputs where to find the report html: <pre><code>...\nFinished report saved to /workspaces/ankaios/target/llvm-cov/html\n</code></pre></p> <p>Note: By the first usage you might be asked for confirmation to install the <code>llvm-tools-preview</code> tool.</p> <p>While writing tests, you may want to execute only the tests in a certain file and check the reached coverage. To do so you can execute:</p> <p>To print out directly into the console:</p> <pre><code>cov test ankaios_server\n</code></pre> <p>Or to produce a report in html:</p> <pre><code>cov test ankaios_server --html\n</code></pre> <p>Once the run is complete, you can check the report to see which lines are not covered yet.</p>"},{"location":"development/unit-verification/","title":"Unit verification","text":"<p>This page defines which tools and processes are used in in this project for the purposes of software unit verification. The unit verification process is performed during implementation phase and is as automated as possible, one exception is the code review which cannot be done automatically. Automated unit test runs are executed by the CI build system as well as during the regular releasing process.</p>"},{"location":"development/unit-verification/#verification-tools-and-procedures","title":"Verification tools and procedures","text":"<p>Ankaios development follows the guidelines specified in the Rust coding guidelines.</p>"},{"location":"development/unit-verification/#code-review","title":"Code review","text":"<p>Code reviews are part of the implementation process and performed before code is merged to the main branch. Contributors create pull requests and request a review s.t. the process can be started. The review is performed by at least one committer who has good knowledge of the area under review. When all applicable review criteria and checklists are passed and reviewer(s) have accepted the change, code can be merged to the main branch.</p>"},{"location":"development/unit-verification/#verification-by-unit-test","title":"Verification by unit test","text":""},{"location":"development/unit-verification/#test-focus-and-goal","title":"Test focus and goal","text":"<p>The objective of the unit test is to confirm the correct internal behavior of a software unit according to the design aspects documented in the SW design. A unit test will test the unit in the target environment by triggering unit methods/functions and verifying the behavior. Stubbed interfaces/mocking techniques can be used to meet the code coverage requirements. This means that unit tests shall be written according to the detailed requirements. Requirement source is SW design.</p>"},{"location":"development/unit-verification/#unit-test-case-naming-convention","title":"Unit test case naming convention","text":"<p>By introducing a naming convention for unit test cases a harmonized test code-base can be achieved. This simplifies reading and understanding the intention of the unit test case. Please see the naming convention defined in Rust coding guidelines.</p>"},{"location":"development/unit-verification/#unit-test-organization","title":"Unit test organization","text":"<p>The unit tests shall be written in the same file as the source code like suggested in the Rust Language Book and shall be prefixed with <code>utest_</code>.</p>"},{"location":"development/unit-verification/#example-for-unit-tests-in-source-file-in-rust","title":"Example for unit tests in source file in Rust","text":"<p>At the end of the file e.g. <code>my_module/src/my_component.rs</code>:</p> <pre><code>...\nfn my_algorithm(input: i32) -&gt; Vec&lt;u8&gt; {\n...\n}\nasync fn my_async_function(input: i32) -&gt; Vec&lt;u8&gt; {\n...\n}\n...\n#[cfg(test)]\nmod tests {\n...\n#[test]\nfn utest_my_algorithm_returns_empty_array_when_input_is_0_or_negative() {\n...\n}\n#[tokio::test]\nasync fn utest_my_async_function_returns_empty_array_when_input_is_0_or_negative() {\n...\n}\n}\n</code></pre>"},{"location":"development/unit-verification/#test-execution-and-reports","title":"Test Execution and Reports","text":"<p>Unit test cases are executed manually by the developer during implementation phase and later automatically in CI builds. Unit test and coverage reports are generated and stored automatically by the CI build system. If unit test case fails before code is merged to main branch (merge verification), the merge is not allowed until the issue is fixed. If unit test case fails after the code is merged to main branch, it is reported via email and fixed via internal Jira ticket reported by the developer.</p> <p>Regression testing is done by the CI build system. </p>"},{"location":"development/unit-verification/#goals-and-metrics","title":"Goals and Metrics","text":"<p>The following table show how test coverage is currently shown in the coverage report:</p> Goal Metric Red Yellow Green Code coverage &lt;80% &gt;80% 100% <p>Currently there is no proper way of explicitly excluding parts of the code from the test coverage report in order to get to an easily observable value of 100%. The explicitly excluded code would have a corresponding comment stating the reason for excluding it. As this is not possible, we would initially target at least 80% line coverage in each file.</p>"},{"location":"reference/_ankaios.proto/","title":"Protocol Documentation","text":""},{"location":"reference/_ankaios.proto/#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p>ankaios.proto</p> <ul> <li>AccessRights</li> <li>AccessRightsRule</li> <li>AddedWorkload</li> <li>AddedWorkload.DependenciesEntry</li> <li>AgentHello</li> <li>CompleteState</li> <li>Cronjob</li> <li>DeletedWorkload</li> <li>DeletedWorkload.DependenciesEntry</li> <li>ExecutionRequest</li> <li>Interval</li> <li>RequestCompleteState</li> <li>State</li> <li>State.ConfigsEntry</li> <li>State.CronjobsEntry</li> <li>State.WorkloadsEntry</li> <li>StateChangeRequest</li> <li>Tag</li> <li>UpdateStateRequest</li> <li>UpdateWorkload</li> <li>UpdateWorkloadState</li> <li>Workload</li> <li>Workload.DependenciesEntry</li> <li> <p>WorkloadState</p> </li> <li> <p>ExecutionState</p> </li> <li>ExpectedState</li> <li>PatchOperation</li> <li> <p>UpdateStrategy</p> </li> <li> <p>AgentConnection</p> </li> <li>CliConnection</li> </ul> </li> <li> <p>Scalar Value Types</p> </li> </ul> <p></p> <p>Top</p>"},{"location":"reference/_ankaios.proto/#ankaiosproto","title":"ankaios.proto","text":"<p>The Ankaios communication protocol is used in the communcation between the following components:</p> <ol> <li> <p>Ankaios Agent and Ankaios Server,</p> </li> <li> <p>Ankaios CLI and Ankaios Server,</p> </li> <li> <p>Workload and Ankaios Server through the control interface.</p> </li> </ol> <p>The protocol consists of the following top-level message types:</p> <ol> <li> <p>StateChangeRequest: agent/cli -&gt; server</p> </li> <li> <p>ExecutionRequest: server -&gt; agent/cli</p> </li> </ol> <p></p>"},{"location":"reference/_ankaios.proto/#accessrights","title":"AccessRights","text":"<p>A message containing lists of access rules that are allowed or denied.</p> Field Type Label Description allow AccessRightsRule repeated A list of access rules that are allowed. deny AccessRightsRule repeated A list of access rules that are denied. <p></p>"},{"location":"reference/_ankaios.proto/#accessrightsrule","title":"AccessRightsRule","text":"<p>A message describing an access rule for the given patch operation for given object fields and values.</p> Field Type Label Description operation PatchOperation The patch operation of interrest. updateMask string repeated A List of field names. value string repeated A list of accepted values. <p></p>"},{"location":"reference/_ankaios.proto/#addedworkload","title":"AddedWorkload","text":"<p>A message containing information about a workload to be added to the Ankaios cluster.</p> Field Type Label Description name string The name of the workload. runtime string The name of the runtime, e.g., podman. dependencies AddedWorkload.DependenciesEntry repeated A list of dependencies to other workloads with their corresponding, expected states. Can be used to enable a synchronized start of a workload. restart bool A flag indicating to restart the workload in case of an intentional or an unintentional stop of the workload. updateStrategy UpdateStrategy An enum to specify the update strategy. accessRights AccessRights Lists of authorizations of the workload. tags Tag repeated A list of tags. runtimeConfig string The configuration information specific to the runtime. <p></p>"},{"location":"reference/_ankaios.proto/#addedworkloaddependenciesentry","title":"AddedWorkload.DependenciesEntry","text":"Field Type Label Description key string value ExpectedState"},{"location":"reference/_ankaios.proto/#agenthello","title":"AgentHello","text":"<p>A message to the Ankaios server to register a new agent.</p> Field Type Label Description agentName string A unique agent name. <p></p>"},{"location":"reference/_ankaios.proto/#completestate","title":"CompleteState","text":"<p>A message containing the complete state of the Ankaios system. This is a response to the RequestCompletestate message.</p> Field Type Label Description requestId string The request id corresponding to a sent RequestCompletestate message. startupState State The State information at the startup of the Ankaios System. currentState State The current state information. workloadStates WorkloadState repeated The current states of the workloads. <p></p>"},{"location":"reference/_ankaios.proto/#cronjob","title":"Cronjob","text":"<p>A message containing the cron job information.</p> Field Type Label Description workload string The name of the workload. interval Interval The interval of the cron job. <p></p>"},{"location":"reference/_ankaios.proto/#deletedworkload","title":"DeletedWorkload","text":"<p>A message containing information about a workload to be deleted from the Anakaios system.</p> Field Type Label Description name string The name of the workload. dependencies DeletedWorkload.DependenciesEntry repeated A list of dependencies to other workloads with their corresponding, expected states. Can be used to enable a synchronized stop of a workload. <p></p>"},{"location":"reference/_ankaios.proto/#deletedworkloaddependenciesentry","title":"DeletedWorkload.DependenciesEntry","text":"Field Type Label Description key string value ExpectedState"},{"location":"reference/_ankaios.proto/#executionrequest","title":"ExecutionRequest","text":"<p>Messages to the Ankaios server.</p> Field Type Label Description updateWorkload UpdateWorkload A message containing lists of workloads to be added or deleted. updateWorkloadState UpdateWorkloadState A message containing list of workload execution states. completeState CompleteState A message containing the complete state (startup state, current state, workload states) of the Anakios system. <p></p>"},{"location":"reference/_ankaios.proto/#interval","title":"Interval","text":"<p>A message containing the interval information for the cron job.</p> Field Type Label Description hours uint32 The number of hours. minutes uint32 The number of minutes. seconds uint32 The number of seconds. <p></p>"},{"location":"reference/_ankaios.proto/#requestcompletestate","title":"RequestCompleteState","text":"<p>A message containing a request for the complete/partial state of the Ankaios system. This is usually answered with a CompleteState message.</p> Field Type Label Description requestId string A request id. This can be any string literal. fieldMask string repeated A list of symbolic field paths within the State message structure e.g. 'current_state.workloads.nginx'. <p></p>"},{"location":"reference/_ankaios.proto/#state","title":"State","text":"<p>A message containing the state information.</p> Field Type Label Description workloads State.WorkloadsEntry repeated A mapping from workload names to workload configurations. configs State.ConfigsEntry repeated A key value storage for reusable configuration items. cronjobs State.CronjobsEntry repeated A mapping from workload names to cron job configurations. <p></p>"},{"location":"reference/_ankaios.proto/#stateconfigsentry","title":"State.ConfigsEntry","text":"Field Type Label Description key string value string"},{"location":"reference/_ankaios.proto/#statecronjobsentry","title":"State.CronjobsEntry","text":"Field Type Label Description key string value Cronjob"},{"location":"reference/_ankaios.proto/#stateworkloadsentry","title":"State.WorkloadsEntry","text":"Field Type Label Description key string value Workload"},{"location":"reference/_ankaios.proto/#statechangerequest","title":"StateChangeRequest","text":"<p>Messages to the Ankaios server.</p> Field Type Label Description agentHello AgentHello This message is for internal usage only! updateWorkloadState UpdateWorkloadState A message to Ankaios server to update the execution state of a workload. updateState UpdateStateRequest A message to Ankaios server to update the State of one or more agent(s). requestCompleteState RequestCompleteState A message to Ankaios server to request the complete state by the given request id and the optional field mask. <p></p>"},{"location":"reference/_ankaios.proto/#tag","title":"Tag","text":"<p>A message to store a tag.</p> Field Type Label Description key string The key of the tag. value string The value of the tag. <p></p>"},{"location":"reference/_ankaios.proto/#updatestaterequest","title":"UpdateStateRequest","text":"<p>A message containing a request to update the state of the Ankaios system. The new state is provided as state object.  To specify which part(s) of the new state object should be updated a list of update mask (same as field mask) paths needs to be provided.</p> Field Type Label Description newState CompleteState The new state of the Ankaios system. updateMask string repeated A list of symbolic field paths within the state message structure e.g. 'current_state.workloads.nginx' to specify what to be updated. <p></p>"},{"location":"reference/_ankaios.proto/#updateworkload","title":"UpdateWorkload","text":"<p>A message providing information about the workloads to be added and/or deleted.</p> Field Type Label Description addedWorkloads AddedWorkload repeated A list of messages containing information about a workload to be added by an Ankaios agent. deletedWorkloads DeletedWorkload repeated A list of messages containing information about a workload to be deleted by an Ankaios agent. <p></p>"},{"location":"reference/_ankaios.proto/#updateworkloadstate","title":"UpdateWorkloadState","text":"<p>A message containing the list the workload states.</p> Field Type Label Description workloadStates WorkloadState repeated A list of workload states. <p></p>"},{"location":"reference/_ankaios.proto/#workload","title":"Workload","text":"<p>A message containing the configuration of a workload.</p> Field Type Label Description agent string The name of the owning Agent. restart bool A flag indicating to restart the workload in case of an intentional or an unintentional stop of the workload. dependencies Workload.DependenciesEntry repeated A map of workload names and expected states to enable a synchronized start of the workload. updateStrategy UpdateStrategy An enum to specify the update strategy. tags Tag repeated A list of tag names. accessRights AccessRights Lists of authorizations of the workload. runtime string The name of the runtime e.g. podman. runtimeConfig string The configuration information specific to the runtime. <p></p>"},{"location":"reference/_ankaios.proto/#workloaddependenciesentry","title":"Workload.DependenciesEntry","text":"Field Type Label Description key string value ExpectedState"},{"location":"reference/_ankaios.proto/#workloadstate","title":"WorkloadState","text":"<p>A message containing the information about the workload state.</p> Field Type Label Description workloadName string The name of the workload. agentName string The name of the owning Agent. executionState ExecutionState The workload execution state. <p></p>"},{"location":"reference/_ankaios.proto/#executionstate","title":"ExecutionState","text":"<p>An enum type describing the workload execution state.</p> Name Number Description EXEC_PENDING 0 The workload is pending. EXEC_RUNNING 1 The workload is running. EXEC_SUCCEEDED 2 The workload has run successfully and is stopped. EXEC_FAILED 3 The workload has failed. EXEC_UNKNOWN 4 The workload is in unknown state. This is the case if the owning agent is disconnected from the Ankaios server. EXEC_REMOVED 5 The workload has been deleted. <p></p>"},{"location":"reference/_ankaios.proto/#expectedstate","title":"ExpectedState","text":"<p>An enum type describing the expected workload state. Used for dependency management.</p> Name Number Description STOPPED 0 The workload is stopped. RUNNING 1 The workload is running. <p></p>"},{"location":"reference/_ankaios.proto/#patchoperation","title":"PatchOperation","text":"<p>An enum type for specifing the patch operation.</p> Name Number Description REPLACE 0 The replace operation. ADD 1 The add operation. REMOVE 2 the remove operation. <p></p>"},{"location":"reference/_ankaios.proto/#updatestrategy","title":"UpdateStrategy","text":"<p>An enum type for specifing the update strategy.</p> Name Number Description UNSPECIFIED 0 The update order is irrelevant. AT_LEAST_ONCE 1 At least one instance shall be running - start the new before stopping the old one. AT_MOST_ONCE 2 At most one instance shall be running - stop the old before starting the new one. <p></p>"},{"location":"reference/_ankaios.proto/#agentconnection","title":"AgentConnection","text":"Method Name Request Type Response Type Description ConnectAgent StateChangeRequest stream ExecutionRequest stream"},{"location":"reference/_ankaios.proto/#cliconnection","title":"CliConnection","text":"Method Name Request Type Response Type Description ConnectCli StateChangeRequest stream ExecutionRequest stream"},{"location":"reference/_ankaios.proto/#scalar-value-types","title":"Scalar Value Types","text":".proto Type Notes C++ Java Python Go C# PHP Ruby  double double double float float64 double float Float  float float float float float32 float float Float  int32 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint32 instead. int32 int int int32 int integer Bignum or Fixnum (as required)  int64 Uses variable-length encoding. Inefficient for encoding negative numbers \u2013 if your field is likely to have negative values, use sint64 instead. int64 long int/long int64 long integer/string Bignum  uint32 Uses variable-length encoding. uint32 int int/long uint32 uint integer Bignum or Fixnum (as required)  uint64 Uses variable-length encoding. uint64 long int/long uint64 ulong integer/string Bignum or Fixnum (as required)  sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32 int int int32 int integer Bignum or Fixnum (as required)  sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64 long int/long int64 long integer/string Bignum  fixed32 Always four bytes. More efficient than uint32 if values are often greater than 2^28. uint32 int int uint32 uint integer Bignum or Fixnum (as required)  fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 2^56. uint64 long int/long uint64 ulong integer/string Bignum  sfixed32 Always four bytes. int32 int int int32 int integer Bignum or Fixnum (as required)  sfixed64 Always eight bytes. int64 long int/long int64 long integer/string Bignum  bool bool boolean boolean bool bool boolean TrueClass/FalseClass  string A string must always contain UTF-8 encoded or 7-bit ASCII text. string String str/unicode string string string String (UTF-8)  bytes May contain any arbitrary sequence of bytes. string ByteString str []byte ByteString string String (ASCII-8BIT)"},{"location":"reference/api/","title":"API","text":"<p>Ankaios offers an API to alter the current state.  The API is constructed with message data structures described in the protocol documentation.  Ankaios provides a gRPC API which can be used during development. The provided ank CLI uses this API, but the API can also be used directly. Ankaios also provides the control interface API to the managed workloads which allows workloads to alter the current/stored state.</p>"},{"location":"reference/complete-state/","title":"Working with CompleteState","text":""},{"location":"reference/complete-state/#completestate","title":"CompleteState","text":"<p>The complete state data structure CompleteState is used for building a request to Ankaios server to change or receive the state of the Ankaios system. It contains the <code>startupState</code> which describes the states provided at the start of the Ankaios system via the startup configuration, the <code>currentState</code> which describes the current state of the Ankaios system and the <code>workloadStates</code> which gives the information about the execution state of all the workloads. By using of CompleteState in conjunction with the object field mask specific parts of the Ankaios state could be retrieved or updated.</p> <p>Example: <code>ank get state</code> returns the complete state of Ankaios system: <pre><code>requestId: ank-cli\nstartupState:\n  workloads: {}\nconfigs: {}\ncronJobs: {}\ncurrentState:\n  workloads:\n    api_sample:\n      agent: agent_A\n      dependencies: {}\nupdateStrategy: AT_MOST_ONCE\n      accessRights:\n        allow: []\ndeny: []\nruntime: podman\n      name: api_sample\n      restart: true\ntags:\n      - key: owner\n        value: Ankaios team\n      runtimeConfig: |\nimage: ankaios_workload_api_example\n    hello3:\n      agent: agent_B\n      dependencies: {}\nupdateStrategy: AT_MOST_ONCE\n      accessRights:\n        allow: []\ndeny: []\nruntime: podman\n      name: hello3\n      restart: true\ntags:\n      - key: owner\n        value: Ankaios team\n      runtimeConfig: |\nimage: alpine:latest\n        command: [\"echo\"]\nargs: [\"Hello Ankaios\"]\nhello1:\n      agent: agent_B\n      dependencies: {}\nupdateStrategy: AT_MOST_ONCE\n      accessRights:\n        allow: []\ndeny: []\nruntime: podman\n      name: hello1\n      restart: true\ntags:\n      - key: owner\n        value: Ankaios team\n      runtimeConfig: |\nimage: alpine:latest\n        command: [\"echo\"]\nargs: [\"Hello Ankaios\"]\nremove: true\nnginx:\n      agent: agent_A\n      dependencies: {}\nupdateStrategy: AT_MOST_ONCE\n      accessRights:\n        allow: []\ndeny: []\nruntime: podman\n      name: nginx\n      restart: true\ntags:\n      - key: owner\n        value: Ankaios team\n      runtimeConfig: |\nimage: docker.io/nginx:latest\n        ports:\n        - containerPort: 80\nhostPort: 8081\nhello2:\n      agent: agent_B\n      dependencies: {}\nupdateStrategy: AT_MOST_ONCE\n      accessRights:\n        allow: []\ndeny: []\nruntime: podman\n      name: hello2\n      restart: true\ntags:\n      - key: owner\n        value: Ankaios team\n      runtimeConfig: |\nimage: alpine:latest\n        command: [\"echo\"]\nargs: [\"Hello Ankaios\"]\nremove: false\nconfigs: {}\ncronJobs: {}\nworkloadStates: []\n</code></pre> It is not necessary to provide the whole structure of the the CompleteState data structure when using it in conjunction with the object field mask. It is sufficient to provide the relevant branch of the CompleteState object. As an example, to change the restart behavior of the nginx workload, only the relevant branch of the CompleteState needs to be provided: <pre><code>currentState:\n  workloads:\n    nginx:\n      restart: false\n</code></pre></p>"},{"location":"reference/complete-state/#object-field-mask","title":"Object field mask","text":"<p>With the object field mask only specific parts of the Ankaios state could be retrieved or updated. The object field mask can be constructed using the field names of the CompleteState data structure: <pre><code>&lt;top level field name&gt;.&lt;second level field name&gt;.&lt;third level field name&gt;.&lt;...&gt;\n</code></pre></p> <ol> <li> <p>Example: <code>ank get state currentState.workloads.nginx</code> returns only the information about nginx workload: <pre><code>currentState:\n  workloads:\n    nginx:\n      agent: agent_A\n      dependencies: {}\nupdateStrategy: AT_MOST_ONCE\n      accessRights:\n        allow: []\ndeny: []\nruntime: podman\n      name: nginx\n      restart: true\ntags:\n      - key: owner\n        value: Ankaios team\n      runtimeConfig: |\nimage: docker.io/nginx:latest\n        ports:\n        - containerPort: 80\nhostPort: 8081\n</code></pre></p> </li> <li> <p>Example <code>ank get state currentState.workloads.nginx.runtimeConfig</code> returns only the runtime configuration of nginx workload: <pre><code>currentState:\n  workloads:\n    nginx:\n      runtimeConfig: |\nimage: docker.io/nginx:latest\n        ports:\n        - containerPort: 80\nhostPort: 8081\n</code></pre></p> </li> <li> <p>Example <code>ank set state -f new-state.yaml currentState.workloads.nginx.restart</code> changes the restart behavior of nginx workload to <code>false</code>: new-state.yaml<pre><code>currentState:\nworkloads:\nnginx:\nrestart: false\n</code></pre></p> </li> </ol>"},{"location":"reference/control-interface/","title":"Control interface","text":"<p>The control interface allows the workload developers to easily integrate the communication between the Ankaios system and their applications.</p>"},{"location":"reference/control-interface/#overview","title":"Overview","text":"<pre><code>---\ntitle: Overview\n---\nflowchart TD\n    a1(Ankaios Agent 1)\n    w1(Workload 1)\n    w2(Workload 2)\n    a2(Ankaios Agent 2)\n    w3(Workload 3)\n    w4(Workload 4)\n    s(Ankaios Server)\n\n\n    s &lt;--&gt; a1 &lt;--&gt;|Control Interface| w1 &amp; w2\n    s &lt;--&gt; a2 &lt;--&gt;|Control Interface| w3 &amp; w4</code></pre> <p>The control interface enables a workload to communicate with the Ankaios system by interacting with the Ankaios server through writing/reading communication data to/from the provided FIFO files in the FIFO mount point. </p>"},{"location":"reference/control-interface/#fifo-mount-point","title":"FIFO mount point","text":"<pre><code>---\ntitle: FIFO Mount Point\n---\nflowchart TD\n    a1(Ankaios Agent 1)\n    w1(Workload 1)\n    w2(Workload 2)\n    s(Ankaios Server)\n\n\n    s &lt;--&gt; a1 &lt;--&gt;|\"/run/ankaios/control_interface/{input,output}\"| w1 &amp; w2</code></pre> <p>The control interface relies on FIFO (also known as named pipes) to enable a workload process to communicate with the Ankaios system. For that purpose, Ankaios creates a mount point for each workload to store the FIFO files. At the mount point <code>/run/ankaios/control_interface/</code> the workload developer can find the FIFO files <code>input</code> and <code>output</code> and use them for the communication with the Ankaios server. Ankaios uses its own communication protocol described in protocol documentation as a protobuf IDL which allows the client code to be generated in any programming language supported by the protobuf compiler. The generated client code can then be integrated and used in a workload.</p>"},{"location":"reference/control-interface/#communication-between-ankaios-and-workloads","title":"Communication between Ankaios and workloads","text":"<pre><code>---\ntitle: Communication between Ankaios and a workload\n---\nflowchart TD\n    proto(\"ankaios.proto\")\n    gen_code(\"Generated Client Code\")\n    workload(\"Workload\")\n\n    proto --&gt;|generate code with protoc| gen_code\n    workload--&gt;|uses| gen_code</code></pre> <p>In order to enable the communication between a workload and the Ankaios system, the workload needs to make use of the control interface by sending and processing serialized messages defined in <code>ankaios.proto</code> via writing to and reading from the provided FIFO files <code>output</code> and <code>input</code> found in the mount point <code>/run/ankaios/control_interface/</code>. By using the protobuf compiler (protoc) code in any programming language supported by the protobuf compiler can be generated. The generated code contains functions for serializing and deserializing the messages to and from the Protocol Buffers binary format.</p>"},{"location":"reference/control-interface/#sending-request-message-from-a-workload-to-ankaios-server","title":"Sending request message from a workload to Ankaios server","text":"<p>To send out a request message from the workload to the Ankaios Server the request message needs to be serialized using the generated serializing function, then encoded using length-delimited wire type format and then written directly into the <code>output</code> FIFO file. The type of request message is StateChangeRequest.</p> <pre><code>---\ntitle: Send request message via control interface\n---\nflowchart TD\n    begin([Start])\n    req_msg(Fill StateChangeRequest message)\n    ser_msg(Serialize StateChangeRequest message using the generated serializing function)\n    enc_bytes(Encode as length-delimited varint)\n    output(\"Write encoded bytes to /run/ankaios/control_interface/output\")\n    fin([end])\n\n    begin --&gt; req_msg\n    req_msg --&gt; ser_msg\n    ser_msg --&gt;enc_bytes\n    enc_bytes --&gt; output\n    output --&gt; fin</code></pre> <p>Code snippet in Rust for sending request message via control interface: <pre><code>use api::proto;\nuse prost::Message;\nuse tokio::{\nfs::File,\nio::{AsyncReadExt, AsyncWriteExt},\n};\n#[tokio::main]\nasync fn main() {\nlet control_interface_mount_point = Path::new(\"/run/ankaios/control_interface\");\nlet out_fifo_location = control_interface_mount_point.join(\"output\");\nlet mut out_fifo = File::create(&amp;out_fifo_location).await.unwrap();\n// Fill StateChangeRequest message\nlet request_msg_update_state = proto::StateChangeRequest {\nstate_change_request_enum: Some(\nproto::state_change_request::StateChangeRequestEnum::UpdateState(\nproto::UpdateStateRequest {\nnew_state: Some(proto::CompleteState {\n..Default::default()\n}),\nupdate_mask: vec![\n\"currentState.workloads.api_sample\".to_string(),\n],\n},\n),\n),\n};\n// Serialize StateChangeRequest message using the generated serializing function\n// and encode as length-delimited varint\n// using encode_length_delimited_to_vec() function provided by prost through code generation\nlet out_bytes = request_msg_update_state.encode_length_delimited_to_vec();\n// Write encoded bytes to /run/ankaios/control_interface/output\nout_fifo\n.write_all(&amp;out_bytes)\n.await\n.unwrap();\n}\n</code></pre></p>"},{"location":"reference/control-interface/#processing-response-message-from-ankaios-server","title":"Processing response message from Ankaios server","text":"<p>To process a response message from the Ankaios Server the workload needs to read out the bytes from the <code>input</code> FIFO file. As the bytes are encoded in length-delimited wire type format with a variable length the length needs to be decoded and extracted first. Then the length can be used to decode and deserialize the read bytes to a response message object for further processing. The type of the response message is ExecutionRequest.</p> <pre><code>---\ntitle: Read response message via control interface\n---\nflowchart TD\n    begin([Start])\n    input(\"Read bytes from /run/ankaios/control_interface/input\")\n    dec_length(Get length from read length delimited varint encoded bytes)\n    deser_msg(Decode and deserialize ExecutionRequest message using decoded length and the generated functions)\n    further_processing(Process ExecutionRequest message object)\n    fin([end])\n\n    begin --&gt; input\n    input --&gt; dec_length\n    dec_length --&gt; deser_msg\n    deser_msg --&gt; further_processing\n    further_processing --&gt; fin</code></pre> <p>Code Snippet in Rust for reading response message via control interface: <pre><code>use api::proto;\nuse prost::Message;\nuse tokio::{\nfs::File,\nio::{AsyncReadExt, AsyncWriteExt},\n};\nasync fn read_protobuf_data(file: &amp;mut File) -&gt; Result&lt;Box&lt;[u8]&gt;, io::Error&gt; {\nlet varint_data = read_varint_data(file).await?;\nlet mut varint_data = Box::new(&amp;varint_data[..]);\n// determine the exact size for exact reading of the bytes later by decoding the varint data\nlet size = prost::encoding::decode_varint(&amp;mut varint_data)? as usize;\nlet mut buf = vec![0; size];\nfile.read_exact(&amp;mut buf[..]).await?; // read exact bytes from file\nOk(buf.into_boxed_slice())\n}\nasync fn read_varint_data(file: &amp;mut File) -&gt; Result&lt;[u8; MAX_VARINT_SIZE], io::Error&gt; {\nlet mut res = [0u8; MAX_VARINT_SIZE];\nfor item in res.iter_mut() {\n*item = file.read_u8().await?;\n// check if signature bit is set to 0 if so it is the last byte to be read\nif *item &amp; 0b10000000 == 0 {\nbreak;\n}\n}\nOk(res)\n}\n#[tokio::main]\nasync fn main() {\nlet control_interface_mount_point = Path::new(\"/run/ankaios/control_interface\");\nlet in_fifo_location = control_interface_mount_point.join(\"input\");    let mut in_fifo = File::open(&amp;in_fifo_location).await.unwrap();\ntokio::spawn(async move {\nprintln!(\"listen to ExecutionRequest ...\");\nloop {\nif let Ok(binary) = read_protobuf_data(&amp;mut in_fifo).await {\nlet proto = proto::ExecutionRequest::decode(&amp;mut Box::new(binary.as_ref()));\nprintln!(\"Got ExecutionRequest: {:#?}\", proto);\n// process received ExecutionRequest response message here ...\n}\n}\n});\n}\n</code></pre></p>"},{"location":"reference/glossary/","title":"Glossary","text":"<p>This glossary is intended to be a comprehensive, uniform list of Ankaios terminology. It consists of technical terms specific to Ankaios, as well as more general terms that provide useful context.</p>"},{"location":"reference/glossary/#node","title":"Node","text":"<p>A machine, either physical or virtual, that provides the necessary prerequisites (e.g. OS) to run an Ankaios server and/or agent.</p>"},{"location":"reference/glossary/#runtime","title":"Runtime","text":"<p>The base an which a workload can be started. For OCI container this is a container runtime or engine. For native applications the runtime is the OS itself.</p>"},{"location":"reference/glossary/#workload","title":"Workload","text":"<p>A functionality that the Ankaios orchestrator can manage (e.g. start, stop). A workload could be packed inside an OCI container (e.g. Podman container) or could also be just a native program (native workload). Ankaios is build to be extensible for different workload types by adding support for other runtimes.</p>"},{"location":"reference/glossary/#container","title":"Container","text":"<p>A container is a lightweight, standalone, executable software package that includes everything needed to run an application, including the binaries, runtime, system libraries and dependencies. Containers provide a consistent and isolated environment for applications to run, ensuring that they behave consistently across different computing environments, from development to testing to production.</p>"},{"location":"reference/glossary/#podman-container","title":"Podman container","text":"<p>A Podman container refers to a container managed by Podman, which is an open-source container engine similar to Docker. Podman aims to provide a simple and secure container management solution for developers and system administrators.</p>"},{"location":"reference/glossary/#native-workload","title":"Native workload","text":"<p>An application developed specifically for a particular platform or operating system (OS). It is designed to run directly on the target platform without the need for bringing in any additional translation or emulation layers.</p>"},{"location":"reference/startup-configuration/","title":"Startup configuration","text":"<p>In the Ankaios system it is mandatory to specify all the nodes and workloads that are going to be run. Currently the startup configuration is provided as a file which is in YAML file format and can be passed to the Ankaios server through a command line argument. Depending on the demands towards Ankaios, the startup configuration can later be provided in a different way.</p>"},{"location":"reference/startup-configuration/#configuration-structure","title":"Configuration structure","text":"<p>The startup configuration is composed of a list of workload specifications within the <code>workloads</code> object. A workload specification must contain the following information:</p> <ul> <li><code>workload name</code>(via field key), specify the workload name to identify the workload in the Ankaios system.</li> <li><code>runtime</code>, specify the type of the runtime. Currently supported value is <code>podman</code>.</li> <li><code>agent</code>, specify the name of the owning agent which is going to execute the workload.</li> <li><code>restart</code>, specify if the workload shall be restarted when it exits. Currently not implemented.</li> <li><code>updateStrategy</code>, specify the update strategy which can be one of the following values:<ul> <li><code>UNSPECIFIED</code></li> <li><code>AT_LEAST_ONCE</code></li> <li><code>AT_MOST_ONCE</code></li> </ul> </li> <li><code>accessRights</code>, specify lists of access rules for <code>allow</code> and <code>deny</code> (currently not implemented and shall be set to empty list for both).</li> <li><code>tags</code>, specify a list of <code>key</code> <code>value</code>  pairs.</li> <li><code>runtimeConfig</code>, specify as a string the configuration for the runtime whose configuration structure is specific for each runtime, e.g., for <code>podman</code> runtime the PodmanRuntimeConfig is used.</li> </ul> <p>Example <code>startup-config.yaml</code> file: <pre><code>workloads:\nnginx: # this is used as the workload name which is 'nginx'\nruntime: podman\nagent: agent_A\nrestart: true\nupdateStrategy: AT_MOST_ONCE\naccessRights:\nallow: []\ndeny: []\ntags:\n- key: owner\nvalue: Ankaios team\nruntimeConfig: |\nimage: docker.io/nginx:latest\nports:\n- containerPort: 80\nhostPort: 8081\napi_sample: # this is used as the workload name which is 'api_sample'\nruntime: podman\nagent: agent_A\nrestart: true\nupdateStrategy: AT_MOST_ONCE\naccessRights:\nallow: []\ndeny: []\ntags:\n- key: owner\nvalue: Ankaios team\nruntimeConfig: |\nimage: ankaios_workload_api_example\n</code></pre></p>"},{"location":"reference/startup-configuration/#podmanruntimeconfig","title":"PodmanRuntimeConfig","text":"<p>The runtime configuration for the <code>podman</code> runtime is specified as followed:</p> Field Type Required Description image string yes Image repository or image id command array of strings no Entrypoint array. Not executed in a shell. The container image's ENTRYPOINT is used if this is not provided. args array of strings no Arguments to the entrypoint. The container image's CMD is used if this is not provided. env object with string values no Key/value pairs provided as environment variables in the container mounts array of Mount no List of mounts ports array of Mapping no List of ports to be exposed remove boolean no Specify whether the container shall be removed after exited networkMode string no Set the network mode for the container (like <code>bridge</code>, <code>host</code>, <code>none</code>) <p>Note: Some fields are optional in the runtime configuration. The Podman uses its default value if such field is not set. </p>"},{"location":"reference/startup-configuration/#mount","title":"Mount","text":"Field Type Required Description destination string yes Mount destination options array of strings no Additional options source string depends on type Mount source type string yes Type of the mount uid_mappings array of IdMap no Mapping from host to container user IDs gid_mappings array of IdMap no Mapping from host to container group IDs"},{"location":"reference/startup-configuration/#idmap","title":"IdMap","text":"Field Type Required Description container_id i64 yes The start of the ID range inside of the container host_id i64 yes The start of the ID range on the host size i64 yes The number of IDs to map"},{"location":"reference/startup-configuration/#mapping","title":"Mapping","text":"Field Type Required Description container_port u16 yes Port inside of the container host_port u16 yes Port on the host"},{"location":"usage/installation/","title":"Installation","text":"<p>Ankaios has been tested with the following Linux distributions. Others might work as well but have not been tested.</p> <ul> <li>Ubuntu 23.04</li> <li>Ubuntu 22.04 LTS</li> <li>Ubuntu 20.04 LTS</li> </ul>"},{"location":"usage/installation/#pre-requisites","title":"Pre-requisites","text":"<p>Ankaios currently requires a Linux OS and is available for x86_64 and arm64 targets. Podman needs to be installed as this is used as  container runtime (see Podman installation instructions).</p>"},{"location":"usage/installation/#installation-methods","title":"Installation methods","text":"<p>There a different ways to install Ankaios.</p>"},{"location":"usage/installation/#setup-with-script","title":"Setup with script","text":"<p>The recommend way to install Ankaios is using the installation script. To install the latest pre-built version of Ankaios into the default installation path <code>/usr/local/bin</code>, please run the following command:</p> <pre><code>curl -sfL https://github.com/eclipse-ankaios/ankaios/releases/latest/download/install.sh | bash -\n</code></pre> <p>The installation process automatically detects the platform and downloads the appropriate binaries.</p> <p>Supported platforms: <code>linux/amd64</code>, <code>linux/arm64</code></p> <p>Note</p> <p>The script requires root privileges to install the pre-built binaries into the default installation path <code>/usr/local/bin</code>. You can set a custom installation path if only non-root privileges are available.</p> <p>The following table shows the optional arguments that can be passed to the script:</p> Supported parameters Description -v &lt;version&gt; e.g. <code>v0.1.0</code>, default: latest version -i &lt;install-path&gt; File path where Ankaios will be installed, default: <code>/usr/local/bin</code> <p>To install a specific version run the following command and substitute <code>&lt;version&gt;</code> with a specific version tag e.g. <code>v0.1.0</code>:</p> <pre><code>curl -sfL https://github.com/eclipse-ankaios/ankaios/releases/download/&lt;version&gt;/install.sh | bash -s -- -v &lt;version&gt;\n</code></pre> <p>For available versions see the list of releases.</p>"},{"location":"usage/installation/#manual-download-of-binaries","title":"Manual download of binaries","text":"<p>As an alternative to the installation script, the pre-built binaries can be downloaded manually from the Ankaios repository here. This is useful if the automatic detection of the platform is failing in case of <code>uname</code> system command is not allowed or supported on the target.</p>"},{"location":"usage/installation/#build-from-source","title":"Build from source","text":"<p>For building Ankaios from source see Build.</p>"},{"location":"usage/quickstart/","title":"Quickstart","text":"<p>If you have not installed Ankaios or build from source already, please follow the instructions here. </p> <p>Ankaios needs a startup configuration that contains all the workloads and their configuration which should be started when Ankaios starts up.</p> <p>Let's create a simple config and store that in <code>state.yaml</code></p> <pre><code>workloads:\nnginx:\nruntime: podman\nagent: agent_A\nrestart: true\nupdateStrategy: AT_MOST_ONCE\naccessRights: # (1)\nallow: []\ndeny: []\ntags:\n- key: owner\nvalue: Ankaios team\nruntimeConfig: |\nimage: docker.io/nginx:latest\nports:\n- containerPort: 80\nhostPort: 8081\n</code></pre> <ol> <li>Note that access rights are currently not implemented.</li> </ol> <p>Before we start Ankaios we need to make sure that Podman is listening on a socket that can be used by Ankaios.</p> <pre><code>systemctl --user start podman.socket\n</code></pre> <p>Then we can start the Ankaios server:</p> <pre><code>ank-server --startup-config state.yaml\n</code></pre> <p>The Ankaios server will read the config but detect that no agent with the name <code>agent_A</code> is available that could start the workload.</p> <p>In a new terminal let's start an agent:</p> <pre><code>ank-agent --name agent_A\n</code></pre> <p>This Ankaios agent will run the workload that has been assigned to it. We can use the Ankaios CLI to check the current state (again in an other terminal):</p> <pre><code>ank get state\n</code></pre> <p>Ankaios also provides adding and removing workloads dynamically. To add another workload call:</p> <pre><code>ank run workload \\\n--runtime podman \\\n--agent agent_A \\\n--config 'image: docker.io/busybox:1.36\nenv:\n  MESSAGE: Hello World!\ncommand:\n- sh\n- -c\n- echo \"$MESSAGE\"\n' helloworld\n</code></pre> <p>We can check the state again with <code>ank get state</code> and see, that the workload <code>helloworld</code> has been added to <code>currentState.workloads</code> and the execution state is available in <code>workloadStates</code>.</p> <p>As the workload had a one time job its state is <code>ExecSucceeded</code> and we can  delete it from the state again with:</p> <pre><code>ank delete workload helloworld\n</code></pre>"}]}